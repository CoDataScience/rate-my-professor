{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the libraries you need\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pattern.en import parsetree, Sentence, modality, sentiment\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a dictionary for interest values. Since interest values appear hierarchical, assign increasing numeric values\n",
    "# from least to most interested.\n",
    "INTEREST_DICT = {\"Meh\" : 0, \"Low\" : 1, \"It's my life\" : 4,\n",
    "                 \"Sorta interested\" : 2, \"Really into it\" : 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to get train/test feature matrices based on what features we want to use\n",
    "def get_features(train, test, features):\n",
    "    train_feature_list = []\n",
    "    test_feature_list = []\n",
    "    for feature in features:\n",
    "        if feature == 'comments':\n",
    "            train[feature].fillna(\"\", inplace=True)\n",
    "            test[feature].fillna('', inplace=True)\n",
    "            train_comments_revised = train[feature]\n",
    "            test_comments_revised = test[feature]\n",
    "            tfv = TfidfVectorizer(ngram_range=(1,3))\n",
    "            tfv = tfv.fit(train_comments_revised)\n",
    "            comments_transformed = tfv.transform(train_comments_revised)\n",
    "            train_feature_list.append(comments_transformed)\n",
    "            test_comments_transformed = tfv.transform(test_comments_revised)\n",
    "            test_feature_list.append(test_comments_transformed)\n",
    "        elif feature == 'dept':\n",
    "            cv = CountVectorizer()\n",
    "            cv = cv.fit(train[feature])\n",
    "            comments_transformed = cv.transform(train[feature])\n",
    "            train_feature_list.append(comments_transformed)\n",
    "            test_comments_transformed = cv.transform(test[feature])\n",
    "            test_feature_list.append(test_comments_transformed)\n",
    "        elif feature == 'interest':\n",
    "            interest_list = np.array([[INTEREST_DICT[x] if x in INTEREST_DICT else -1]\n",
    "                             for x in train[feature]])\n",
    "            train_feature_list.append(interest_list)\n",
    "            test_interest_list = np.array([[INTEREST_DICT[x] if x in INTEREST_DICT else -1]\n",
    "                             for x in test[feature]])\n",
    "            test_feature_list.append(test_interest_list)\n",
    "        \n",
    "        # Assuming all other features will not need to be pre-processed\n",
    "        else:\n",
    "            if feature in train:\n",
    "                train_feature_list.append(np.array([[x] for x in train[feature].values]))\n",
    "                test_feature_list.append(np.array([[x] for x in test[feature].values]))\n",
    "    if len(features) == 1:\n",
    "        return train_feature_list[0], test_feature_list[0]\n",
    "    \n",
    "    # Need to use a sparse matrix if Count or TfIdf Vectorizers are used\n",
    "    if 'comments' in features or 'dept' in features:\n",
    "        return sp.sparse.hstack((train_feature_list), format='csr'), sp.sparse.hstack((test_feature_list), format='csr')\n",
    "    else:\n",
    "        return np.concatenate((train_feature_list), axis=1), np.concatenate((test_feature_list), axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "        data = pd.read_csv('train.csv')\n",
    "        train, test = train_test_split(data, test_size=0.20)\n",
    "        features = ['comments', 'interest']\n",
    "        model = Ridge(solver='auto')\n",
    "        \n",
    "        # This could take a while due to the n_gram range of (1,3) in the TfIdfVectorizer\n",
    "        train_data, test_data = get_features(train, test, features)\n",
    "        \n",
    "        # Make lists for subjectivity, polarity, and modality features\n",
    "        train_subjectivities = []\n",
    "        test_subjectivities = []\n",
    "        train_polarities = []\n",
    "        test_polarities = []\n",
    "        train_modalities = []\n",
    "        test_modalities = []\n",
    "        for comment in train['comments']:\n",
    "            comment_sentiment = sentiment(comment)\n",
    "            # sentiment returns a tuple of (polarity, subjectivity)\n",
    "            train_polarities.append([comment_sentiment[0]])\n",
    "            train_subjectivities.append([comment_sentiment[1]])\n",
    "            train_modalities.append([modality(comment)])\n",
    "        train_polarities = np.array(train_polarities)\n",
    "        train_subjectivities = np.array(train_subjectivities)\n",
    "        train_modalities = np.array(train_modalities)\n",
    "        \n",
    "        for comment in test['comments']:\n",
    "            comment_sentiment = sentiment(comment)\n",
    "            # sentiment returns a tuple of (polarity, subjectivity)\n",
    "            test_polarities.append([comment_sentiment[0]])\n",
    "            test_subjectivities.append([comment_sentiment[1]])\n",
    "            test_modalities.append([modality(comment)])\n",
    "        test_polarities = np.array(test_polarities)\n",
    "        test_subjectivities = np.array(test_subjectivities)\n",
    "        test_modalities = np.array(test_modalities)\n",
    "        \n",
    "        train_data = sp.sparse.hstack((train_data, train_polarities, train_subjectivities,\n",
    "                                       train_modalities), format='csr')\n",
    "        test_data = sp.sparse.hstack((test_data, test_polarities, test_subjectivities,\n",
    "                                       test_modalities), format='csr')\n",
    "        regressor = Ridge(solver='auto')\n",
    "        model = regressor.fit(train_data, train['quality'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.52939253864\n"
     ]
    }
   ],
   "source": [
    "        predictions = model.predict(test_data)\n",
    "        # Apply a floor/ceiling function to predictions to keep them in the range (2, 10)\n",
    "        new_predictions = [2 if x < 2 else 10 if x > 10 else x for x in predictions]\n",
    "        new_predictions = np.array(new_predictions)\n",
    "        mse = mean_squared_error(test['quality'], new_predictions)\n",
    "        print(\"MSE: {}\".format(mse))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
